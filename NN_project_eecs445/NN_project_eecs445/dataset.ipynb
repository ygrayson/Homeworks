{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Jupyter Notebook for EECS 445 - Intro to Machine Learning, Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EECS 445 - Introduction to Machine Learning\n",
    "Fall 2019 - Project 2\n",
    "Posters Dataset\n",
    "    Class wrapper for interfacing with the dataset of movie poster images\n",
    "\"\"\"\n",
    "\n",
    "#path = \"C://Users//yinqi//Documents//Qianbo's Folder//UNDERGRADUATE//UMICH!!!//ACADEMICS//STUDY!!!//6_2019 FALL//EECS 445 - Machine Learning//Project//2//project2\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_loaders(num_classes):\n",
    "    tr, va, te, _ = get_train_val_dataset(num_classes=num_classes)\n",
    "\n",
    "    batch_size = config('cnn.batch_size')\n",
    "    tr_loader = DataLoader(tr, batch_size=batch_size, shuffle=True)\n",
    "    va_loader = DataLoader(va, batch_size=batch_size, shuffle=False)\n",
    "    te_loader = DataLoader(te, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return tr_loader, va_loader, te_loader, tr.get_semantic_label\n",
    "\n",
    "\n",
    "\n",
    "class PostersDataset(Dataset):\n",
    "\n",
    "    def __init__(self, partition, num_classes=10):\n",
    "        \"\"\"\n",
    "        Reads in the necessary data from disk.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if partition not in ['train', 'val', 'test']:\n",
    "            raise ValueError('Partition {} does not exist'.format(partition))\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.partition = partition\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Load in all the data we need from disk\n",
    "        self.metadata = pd.read_csv(config('csv_file'))\n",
    "        self.X, self.y = self._load_data()\n",
    "\n",
    "        self.semantic_labels = dict(zip(\n",
    "            self.metadata['numeric_label'],\n",
    "            self.metadata['semantic_label']\n",
    "        ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx]).float(), torch.tensor(self.y[idx]).long()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Loads a single data partition from file.\n",
    "        \"\"\"\n",
    "        print(\"loading %s...\" % self.partition)\n",
    "\n",
    "        if self.partition == 'test':\n",
    "            if self.num_classes == 5:\n",
    "                df = self.metadata[self.metadata.partition == self.partition]\n",
    "            elif self.num_classes == 10:\n",
    "                df = self.metadata[self.metadata.partition.isin([self.partition, ' '])]\n",
    "            else:\n",
    "                raise ValueError('Unsupported test partition: num_classes must be 5 or 10')\n",
    "        else:\n",
    "            df = self.metadata[\n",
    "                (self.metadata.numeric_label < self.num_classes) &\n",
    "                (self.metadata.partition == self.partition)\n",
    "            ]\n",
    "\n",
    "        X, y = [], []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row['numeric_label']\n",
    "            image = imread(os.path.join(config('image_path'), row['filename']), pilmode='RGB')\n",
    "            X.append(image)\n",
    "            y.append(row['numeric_label'])\n",
    "\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def get_semantic_label(self, numeric_label):\n",
    "        \"\"\"\n",
    "        Returns the string representation of the numeric class label (e.g.,\n",
    "        the numberic label 1 maps to the semantic label 'miniature_poodle').\n",
    "        \"\"\"\n",
    "        return self.semantic_labels[numeric_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell contains my inplementation, subject to changes\n",
    "\n",
    "\n",
    "def resize(X):\n",
    "    \"\"\"\n",
    "    Resizes the data partition X to the size specified in the config file.\n",
    "    Uses bicubic interpolation for resizing.\n",
    "    X - multi-dimensional numpy array, each X[i] is the ith poster input\n",
    "\n",
    "    Returns:\n",
    "        the resized images as a numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # DONE: Complete this function\n",
    "    image_dim = config('image_dim')\n",
    "\n",
    "    resized = np.array([])\n",
    "    for idx, img in enumerate(X):\n",
    "        pillow_im = Image.fromarray(img)\n",
    "        pillow_im.resize((image_dim, image_dim), resample=Image.BICUBIC)\n",
    "        # augment into the new numpy array\n",
    "        resized.append(np.array(pillow_im))\n",
    "\n",
    "    print(resized.shape())\n",
    "    return resized\n",
    "\n",
    "class ImageStandardizer(object):\n",
    "    \"\"\"\n",
    "    Channel-wise standardization for batch of images to mean 0 and variance 1.\n",
    "    The mean and standard deviation parameters are computed in `fit(X)` and\n",
    "    applied using `transform(X)`.\n",
    "\n",
    "    X has shape (N, image_height, image_width, color_channel), always takein and not member variable\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image_mean = None\n",
    "        self.image_std = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # DONE: Complete this function\n",
    "        #self.image_mean = X.mean(axis=(0, 1, 2))\n",
    "\n",
    "\n",
    "        # find RGB variance for all poster image\n",
    "        variance = np.var(X)\n",
    "        print(variance)\n",
    "\n",
    "        \"\"\"\n",
    "        total_square = [0, 0, 0]\n",
    "        for poster_img in X:\n",
    "            length = len(poster_img)\n",
    "            width = len(poster_img[0])\n",
    "            for i in range(length):\n",
    "                for j in range(width):\n",
    "                    total_square[0] += (poster_img[i][j][0] - self.image_mean[0]) ** 2\n",
    "                    total_square[1] += (poster_img[i][j][1] - self.image_mean[1]) ** 2\n",
    "                    total_square[2] += (poster_img[i][j][2] - self.image_mean[2]) ** 2\n",
    "        \n",
    "        #self.image_std is [std_R, std_G, std_B] for all training dataset\n",
    "        self.image_std = (total_square / total_entry) ** 0.5\n",
    "        \"\"\"\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        input X - the whole dataset(training/validation/testing)\n",
    "        transform the dataset according to self.mean and self.std. Normalize the whole dataset\n",
    "        return normalized_X, same dimension as X but after normalization\n",
    "        \"\"\"\n",
    "        normalized_X = np.zeros_like(X)\n",
    "        # DONE: Complete this function\n",
    "        for idx in range(len(X)):\n",
    "            for i in range(len(X[0])):\n",
    "                for j in range(len(X[0][0])):\n",
    "                    for k in range(3):\n",
    "                        # normalize each channel (RGB) with regarding to its mean and std\n",
    "                        normalized_X[idx][i][j][k] = (X[idx][i][j][k] - self.image_mean[k]) / self.image_std[k]\n",
    "\n",
    "        return normalized_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...\n"
     ]
    }
   ],
   "source": [
    "# Load Data, no need to run repeatedly\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# load data\n",
    "num_classes=10\n",
    "tr = PostersDataset('train', num_classes) #training set\n",
    "va = PostersDataset('val', num_classes) #validation set\n",
    "te = PostersDataset('test', num_classes) #testing set\n",
    "\n",
    "print(\"Load Data Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resizing...\n",
      "(7200, 268, 182, 3)\n",
      "(268, 182, 3)\n",
      "After Resizing...\n",
      "(7200, 268, 182, 3)\n",
      "Before Resizing...\n",
      "(1800, 268, 182, 3)\n",
      "(268, 182, 3)\n",
      "After Resizing...\n",
      "(1800, 268, 182, 3)\n",
      "Before Resizing...\n",
      "(1000, 268, 182, 3)\n",
      "(268, 182, 3)\n",
      "After Resizing...\n",
      "(1000, 268, 182, 3)\n",
      "Resize Done\n"
     ]
    }
   ],
   "source": [
    "# Resize\n",
    "tr.X = resize(tr.X)\n",
    "va.X = resize(va.X)\n",
    "te.X = resize(te.X)\n",
    "\n",
    "print(\"Resize Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (7200, 268, 182, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-f97937360e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Standardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstandardizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageStandardizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstandardizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fit done\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstandardizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstandardizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-1a1ddbb583c7>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# find RGB variance for all poster image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m   3504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3505\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m-> 3506\u001b[1;33m                          **kwargs)\n\u001b[0m\u001b[0;32m   3507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;31m# not a scalar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (7200, 268, 182, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "# Standardize\n",
    "standardizer = ImageStandardizer()\n",
    "standardizer.fit(tr.X)\n",
    "print(\"Fit done\", standardizer.image_mean, standardizer.image_std)\n",
    "tr.X = standardizer.transform(tr.X)\n",
    "va.X = standardizer.transform(va.X)\n",
    "te.X = standardizer.transform(te.X)\n",
    "\n",
    "# Transpose the dimensions from (N,H,W,C) to (N,C,H,W)\n",
    "tr.X = tr.X.transpose(0,3,1,2)\n",
    "va.X = va.X.transpose(0,3,1,2)\n",
    "te.X = te.X.transpose(0,3,1,2)\n",
    "\n",
    "\n",
    "print(\"Train:\\t\", len(tr.X))\n",
    "print(\"Val:\\t\", len(va.X))\n",
    "print(\"Test:\\t\", len(te.X))\n",
    "print(\"Mean:\", standardizer.image_mean)\n",
    "print(\"Std: \", standardizer.image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
